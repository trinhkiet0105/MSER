{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "lib_path = os.path.abspath(\"\").replace(\"notebooks\", \"src\")\n",
    "sys.path.append(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import BertTokenizer, RobertaTokenizer,AutoTokenizer\n",
    "\n",
    "from configs.base import Config\n",
    "from data.dataloader import build_train_test_dataset\n",
    "from models import losses, networks\n",
    "from trainer import Trainer\n",
    "from utils.configs import get_options\n",
    "from utils.torch.callbacks import CheckpointsCallback\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 09:01:36,810 - root - INFO - Initializing model...\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "opt = get_options(f\"{lib_path}/configs/bert_vggish.py\")\n",
    "logging.info(\"Initializing model...\")\n",
    "# Model\n",
    "try:\n",
    "    network = getattr(networks, opt.model_type)(\n",
    "        num_classes=opt.num_classes,\n",
    "        num_attention_head=opt.num_attention_head,\n",
    "        dropout=opt.dropout,\n",
    "        text_encoder_type=opt.text_encoder_type,\n",
    "        text_encoder_dim=opt.text_encoder_dim,\n",
    "        text_unfreeze=opt.text_unfreeze,\n",
    "        audio_encoder_type=opt.audio_encoder_type,\n",
    "        audio_encoder_dim=opt.audio_encoder_dim,\n",
    "        audio_unfreeze=opt.audio_unfreeze,\n",
    "        audio_norm_type=opt.audio_norm_type,\n",
    "        fusion_head_output_type=opt.fusion_head_output_type,\n",
    "    )\n",
    "    network.to(device)\n",
    "except AttributeError:\n",
    "    raise NotImplementedError(\"Model {} is not implemented\".format(opt.model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMSERA(\n",
       "  (text_encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (audio_encoder): VGGish(\n",
       "    (vggish): VGG(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (9): ReLU(inplace=True)\n",
       "        (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (12): ReLU(inplace=True)\n",
       "        (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (14): ReLU(inplace=True)\n",
       "        (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (embeddings): Sequential(\n",
       "        (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (3): ReLU(inplace=True)\n",
       "        (4): Linear(in_features=4096, out_features=128, bias=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (audio_encoder_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (text_attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (text_linear): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (text_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fusion_attention): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fusion_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fusion_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (classifer): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 09:01:44,376 - root - INFO - Initializing checkpoint directory and dataset...\n",
      "2023-10-13 09:01:44,992 - root - INFO - \n",
      "             audio_encoder_dim: 128                                     \n",
      "            audio_encoder_type: vggish                                  \n",
      "              audio_max_length: 50                                      \n",
      "               audio_norm_type: layer_norm                              \n",
      "                audio_unfreeze: False                                   \n",
      "                    batch_size: 4                                       \n",
      "                checkpoint_dir: d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\n",
      "                     data_root: D:/MELD/MELD                            \n",
      "                       dropout: 0.5                                     \n",
      "                      feat_dim: 2048                                    \n",
      "              focal_loss_alpha: None                                    \n",
      "              focal_loss_gamma: 0.5                                     \n",
      "       fusion_head_output_type: mean                                    \n",
      "                      lambda_c: 1.0                                     \n",
      "                 learning_rate: 0.0001                                  \n",
      "           learning_rate_gamma: 0.1                                     \n",
      "       learning_rate_step_size: 30                                      \n",
      "                     loss_type: CrossEntropyLoss                        \n",
      "                margin_loss_m1: 1.0                                     \n",
      "                margin_loss_m2: 0.5                                     \n",
      "                margin_loss_m3: 0.0                                     \n",
      "             margin_loss_scale: 64.0                                    \n",
      "                   max_to_keep: 1                                       \n",
      "                    model_type: MMSERA                                  \n",
      "                          name: bert_vggish_MMSERA                      \n",
      "            num_attention_head: 8                                       \n",
      "                   num_classes: 4                                       \n",
      "                    num_epochs: 10                                      \n",
      "              optim_attributes: None                                    \n",
      "                        resume: False                                   \n",
      "                   resume_path: D:/SER_ICIIT_2024/notebooks/checkpoints/bert_vggish_MMSERA/20230928-020711/weights/checkpoint_35_132000.pt\n",
      "               save_all_states: True                                    \n",
      "                 save_best_val: True                                    \n",
      "                     save_freq: 4000                                    \n",
      "              text_encoder_dim: 768                                     \n",
      "             text_encoder_type: roberta                                 \n",
      "               text_max_length: 297                                     \n",
      "                 text_unfreeze: False                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.info(\"Initializing checkpoint directory and dataset...\")\n",
    "if opt.text_encoder_type == \"bert\":\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "elif opt.text_encoder_type == \"roberta\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "else:\n",
    "    raise NotImplementedError(\"Tokenizer {} is not implemented\".format(opt.text_encoder_type))\n",
    "\n",
    "# Preapre the checkpoint directory\n",
    "opt.checkpoint_dir = checkpoint_dir = os.path.join(\n",
    "    os.path.abspath(opt.checkpoint_dir),\n",
    "    opt.name,\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "log_dir = os.path.join(checkpoint_dir, \"logs\")\n",
    "weight_dir = os.path.join(checkpoint_dir, \"weights\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(weight_dir, exist_ok=True)\n",
    "opt.save(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "train_ds, test_ds = build_train_test_dataset(\n",
    "    opt.data_root,\n",
    "    opt.batch_size,\n",
    "    tokenizer,\n",
    "    opt.audio_max_length,\n",
    "    text_max_length=opt.text_max_length,\n",
    "    audio_encoder_type=opt.audio_encoder_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 09:01:57,382 - root - INFO - Initializing trainer...\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Initializing trainer...\")\n",
    "if opt.loss_type == \"FocalLoss\":\n",
    "    criterion = losses.FocalLoss(gamma=opt.focal_loss_gamma, alpha=opt.focal_loss_alpha)\n",
    "    criterion.to(device)\n",
    "else:\n",
    "    try:\n",
    "        criterion = getattr(losses, opt.loss_type)(\n",
    "            feat_dim=opt.feat_dim,\n",
    "            num_classes=opt.num_classes,\n",
    "            lambda_c=opt.lambda_c,\n",
    "        )\n",
    "        criterion.to(device)\n",
    "    except AttributeError:\n",
    "        raise NotImplementedError(\"Loss {} is not implemented\".format(opt.loss_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    network=network,\n",
    "    criterion=criterion,\n",
    "    log_dir=opt.checkpoint_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-13 09:01:57,428 - root - INFO - Start training...\n",
      "2023-10-13 09:01:59,039 - root - WARNING - When save_best_val is True, please make sure that you pass the validation data to the trainer.fit() method.\n",
      "                            Otherwise, the best model will not be saved.\n",
      "                            The model will save the lowest validation value if the metric starts with 'loss' and the highest value otherwise.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start training...\")\n",
    "# Build optimizer and criterion\n",
    "optimizer = optim.Adam(params=trainer.network.parameters(), lr=opt.learning_rate)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=opt.learning_rate_step_size, gamma=opt.learning_rate_gamma)\n",
    "\n",
    "ckpt_callback = CheckpointsCallback(\n",
    "    checkpoint_dir=weight_dir,\n",
    "    save_freq=opt.save_freq,\n",
    "    max_to_keep=opt.max_to_keep,\n",
    "    save_best_val=opt.save_best_val,\n",
    "    save_all_states=opt.save_all_states,\n",
    ")\n",
    "trainer.compile(optimizer=optimizer, scheduler=lr_scheduler)\n",
    "if opt.resume:\n",
    "    trainer.load_all_states(opt.resume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "2023-10-13 09:02:00,063 - Training - INFO - Epoch 0/10\n",
      "loss: 2.0044 acc: 0.0000 : : 1522it [06:04,  4.17it/s]                         \n",
      "Epoch 0 - loss: 1.0566\n",
      "2023-10-13 09:08:04,752 - Training - INFO - Epoch 0 - loss: 1.0566\n",
      "Epoch 0 - acc: 0.5828\n",
      "2023-10-13 09:08:04,752 - Training - INFO - Epoch 0 - acc: 0.5828\n",
      "Performing validation...\n",
      "2023-10-13 09:08:04,771 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.64it/s]\n",
      "Validation: loss: 1.0861 acc: 0.5803 \n",
      "2023-10-13 09:08:58,699 - Training - INFO - Validation: loss: 1.0861 acc: 0.5803 \n",
      "Model loss improve from inf to 1.0861458885037671, Saving model...\n",
      "2023-10-13 09:08:58,709 - Training - INFO - Model loss improve from inf to 1.0861458885037671, Saving model...\n",
      "Model acc improve from inf to 0.5802650957290133, Saving model...\n",
      "2023-10-13 09:09:28,220 - Training - INFO - Model acc improve from inf to 0.5802650957290133, Saving model...\n",
      "Epoch 1/10\n",
      "2023-10-13 09:09:58,464 - Training - INFO - Epoch 1/10\n",
      "loss: 2.0888 acc: 0.0000 : : 1522it [05:38,  4.50it/s]                        \n",
      "Epoch 1 - loss: 1.0238\n",
      "2023-10-13 09:15:36,730 - Training - INFO - Epoch 1 - loss: 1.0238\n",
      "Epoch 1 - acc: 0.6060\n",
      "2023-10-13 09:15:36,732 - Training - INFO - Epoch 1 - acc: 0.6060\n",
      "Performing validation...\n",
      "2023-10-13 09:15:36,740 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.72it/s]\n",
      "Validation: loss: 1.0706 acc: 0.5832 \n",
      "2023-10-13 09:16:30,206 - Training - INFO - Validation: loss: 1.0706 acc: 0.5832 \n",
      "Model loss improve from 1.0861458885037671 to 1.0705710303844864, Saving model...\n",
      "2023-10-13 09:16:30,206 - Training - INFO - Model loss improve from 1.0861458885037671 to 1.0705710303844864, Saving model...\n",
      "Model acc improve from 0.5802650957290133 to 0.5832106038291606, Saving model...\n",
      "2023-10-13 09:16:59,434 - Training - INFO - Model acc improve from 0.5802650957290133 to 0.5832106038291606, Saving model...\n",
      "Epoch 2/10\n",
      "2023-10-13 09:17:30,035 - Training - INFO - Epoch 2/10\n",
      "loss: 0.7172 acc: 0.7500 :  63%|######3   | 959/1521 [03:33<02:03,  4.55it/s]Saving model at step 4000\n",
      "2023-10-13 09:21:03,599 - Training - INFO - Saving model at step 4000\n",
      "loss: 1.6825 acc: 0.0000 : : 1522it [06:10,  4.11it/s]                         \n",
      "Epoch 2 - loss: 1.0033\n",
      "2023-10-13 09:23:40,380 - Training - INFO - Epoch 2 - loss: 1.0033\n",
      "Epoch 2 - acc: 0.6118\n",
      "2023-10-13 09:23:40,380 - Training - INFO - Epoch 2 - acc: 0.6118\n",
      "Performing validation...\n",
      "2023-10-13 09:23:40,388 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.74it/s]\n",
      "Validation: loss: 1.0365 acc: 0.6156 \n",
      "2023-10-13 09:24:33,804 - Training - INFO - Validation: loss: 1.0365 acc: 0.6156 \n",
      "Model loss improve from 1.0705710303844864 to 1.0364690086364043, Saving model...\n",
      "2023-10-13 09:24:33,807 - Training - INFO - Model loss improve from 1.0705710303844864 to 1.0364690086364043, Saving model...\n",
      "Model acc improve from 0.5832106038291606 to 0.6156111929307806, Saving model...\n",
      "2023-10-13 09:25:05,436 - Training - INFO - Model acc improve from 0.5832106038291606 to 0.6156111929307806, Saving model...\n",
      "Epoch 3/10\n",
      "2023-10-13 09:25:34,259 - Training - INFO - Epoch 3/10\n",
      "loss: 1.5705 acc: 0.5000 : : 1522it [05:41,  4.46it/s]                        \n",
      "Epoch 3 - loss: 0.9780\n",
      "2023-10-13 09:31:15,430 - Training - INFO - Epoch 3 - loss: 0.9780\n",
      "Epoch 3 - acc: 0.6215\n",
      "2023-10-13 09:31:15,430 - Training - INFO - Epoch 3 - acc: 0.6215\n",
      "Performing validation...\n",
      "2023-10-13 09:31:15,447 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.77it/s]\n",
      "Validation: loss: 1.0288 acc: 0.5979 \n",
      "2023-10-13 09:32:11,803 - Training - INFO - Validation: loss: 1.0288 acc: 0.5979 \n",
      "Model loss improve from 1.0364690086364043 to 1.0288199957718027, Saving model...\n",
      "2023-10-13 09:32:11,803 - Training - INFO - Model loss improve from 1.0364690086364043 to 1.0288199957718027, Saving model...\n",
      "Epoch 4/10\n",
      "2023-10-13 09:32:43,065 - Training - INFO - Epoch 4/10\n",
      "loss: 1.5694 acc: 0.0000 : : 1522it [05:42,  4.45it/s]                        \n",
      "Epoch 4 - loss: 0.9653\n",
      "2023-10-13 09:38:25,170 - Training - INFO - Epoch 4 - loss: 0.9653\n",
      "Epoch 4 - acc: 0.6313\n",
      "2023-10-13 09:38:25,170 - Training - INFO - Epoch 4 - acc: 0.6313\n",
      "Performing validation...\n",
      "2023-10-13 09:38:25,170 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.75it/s]\n",
      "Validation: loss: 1.0317 acc: 0.6097 \n",
      "2023-10-13 09:39:21,743 - Training - INFO - Validation: loss: 1.0317 acc: 0.6097 \n",
      "Epoch 5/10\n",
      "2023-10-13 09:39:21,760 - Training - INFO - Epoch 5/10\n",
      "loss: 0.7814 acc: 0.7500 :  26%|##6       | 396/1521 [01:28<04:00,  4.69it/s]Saving model at step 8000\n",
      "2023-10-13 09:40:50,412 - Training - INFO - Saving model at step 8000\n",
      "Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_2_4000.pt\n",
      "2023-10-13 09:41:19,340 - Training - INFO - Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_2_4000.pt\n",
      "loss: 1.3527 acc: 0.0000 : : 1522it [06:10,  4.11it/s]                         \n",
      "Epoch 5 - loss: 0.9494\n",
      "2023-10-13 09:45:32,526 - Training - INFO - Epoch 5 - loss: 0.9494\n",
      "Epoch 5 - acc: 0.6400\n",
      "2023-10-13 09:45:32,526 - Training - INFO - Epoch 5 - acc: 0.6400\n",
      "Performing validation...\n",
      "2023-10-13 09:45:32,526 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.77it/s]\n",
      "Validation: loss: 1.0246 acc: 0.6112 \n",
      "2023-10-13 09:46:25,853 - Training - INFO - Validation: loss: 1.0246 acc: 0.6112 \n",
      "Model loss improve from 1.0288199957718027 to 1.0245949201318758, Saving model...\n",
      "2023-10-13 09:46:25,865 - Training - INFO - Model loss improve from 1.0288199957718027 to 1.0245949201318758, Saving model...\n",
      "Epoch 6/10\n",
      "2023-10-13 09:46:55,159 - Training - INFO - Epoch 6/10\n",
      "loss: 1.4341 acc: 0.5000 : : 1522it [05:41,  4.46it/s]                        \n",
      "Epoch 6 - loss: 0.9421\n",
      "2023-10-13 09:52:36,230 - Training - INFO - Epoch 6 - loss: 0.9421\n",
      "Epoch 6 - acc: 0.6418\n",
      "2023-10-13 09:52:36,230 - Training - INFO - Epoch 6 - acc: 0.6418\n",
      "Performing validation...\n",
      "2023-10-13 09:52:36,247 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.73it/s]\n",
      "Validation: loss: 1.0134 acc: 0.6274 \n",
      "2023-10-13 09:53:29,710 - Training - INFO - Validation: loss: 1.0134 acc: 0.6274 \n",
      "Model loss improve from 1.0245949201318758 to 1.0133704287336045, Saving model...\n",
      "2023-10-13 09:53:29,710 - Training - INFO - Model loss improve from 1.0245949201318758 to 1.0133704287336045, Saving model...\n",
      "Model acc improve from 0.6156111929307806 to 0.6273932253313697, Saving model...\n",
      "2023-10-13 09:53:59,747 - Training - INFO - Model acc improve from 0.6156111929307806 to 0.6273932253313697, Saving model...\n",
      "Epoch 7/10\n",
      "2023-10-13 09:54:30,647 - Training - INFO - Epoch 7/10\n",
      "loss: 0.8602 acc: 0.7500 :  89%|########9 | 1354/1521 [05:04<00:37,  4.44it/s]Saving model at step 12000\n",
      "2023-10-13 09:59:34,748 - Training - INFO - Saving model at step 12000\n",
      "Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_5_8000.pt\n",
      "2023-10-13 10:00:03,593 - Training - INFO - Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_5_8000.pt\n",
      "loss: 1.2250 acc: 0.5000 : : 1522it [06:10,  4.11it/s]                        \n",
      "Epoch 7 - loss: 0.9294\n",
      "2023-10-13 10:00:41,342 - Training - INFO - Epoch 7 - loss: 0.9294\n",
      "Epoch 7 - acc: 0.6441\n",
      "2023-10-13 10:00:41,359 - Training - INFO - Epoch 7 - acc: 0.6441\n",
      "Performing validation...\n",
      "2023-10-13 10:00:41,363 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.78it/s]\n",
      "Validation: loss: 1.0290 acc: 0.6112 \n",
      "2023-10-13 10:01:34,641 - Training - INFO - Validation: loss: 1.0290 acc: 0.6112 \n",
      "Epoch 8/10\n",
      "2023-10-13 10:01:34,641 - Training - INFO - Epoch 8/10\n",
      "loss: 1.4539 acc: 0.0000 : : 1522it [05:41,  4.46it/s]                        \n",
      "Epoch 8 - loss: 0.9210\n",
      "2023-10-13 10:07:16,018 - Training - INFO - Epoch 8 - loss: 0.9210\n",
      "Epoch 8 - acc: 0.6519\n",
      "2023-10-13 10:07:16,018 - Training - INFO - Epoch 8 - acc: 0.6519\n",
      "Performing validation...\n",
      "2023-10-13 10:07:16,018 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.73it/s]\n",
      "Validation: loss: 1.0003 acc: 0.6200 \n",
      "2023-10-13 10:08:09,496 - Training - INFO - Validation: loss: 1.0003 acc: 0.6200 \n",
      "Model loss improve from 1.0133704287336045 to 1.0003028726191514, Saving model...\n",
      "2023-10-13 10:08:09,496 - Training - INFO - Model loss improve from 1.0133704287336045 to 1.0003028726191514, Saving model...\n",
      "Epoch 9/10\n",
      "2023-10-13 10:08:40,974 - Training - INFO - Epoch 9/10\n",
      "loss: 1.1533 acc: 0.5000 : : 1522it [05:42,  4.44it/s]                        \n",
      "Epoch 9 - loss: 0.9205\n",
      "2023-10-13 10:14:23,941 - Training - INFO - Epoch 9 - loss: 0.9205\n",
      "Epoch 9 - acc: 0.6547\n",
      "2023-10-13 10:14:23,958 - Training - INFO - Epoch 9 - acc: 0.6547\n",
      "Performing validation...\n",
      "2023-10-13 10:14:23,962 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.78it/s]\n",
      "Validation: loss: 1.0100 acc: 0.6171 \n",
      "2023-10-13 10:15:17,229 - Training - INFO - Validation: loss: 1.0100 acc: 0.6171 \n",
      "Epoch 10/10\n",
      "2023-10-13 10:15:17,232 - Training - INFO - Epoch 10/10\n",
      "loss: 0.8821 acc: 0.7500 :  52%|#####2    | 791/1521 [02:57<02:57,  4.12it/s]Saving model at step 16000\n",
      "2023-10-13 10:18:14,890 - Training - INFO - Saving model at step 16000\n",
      "Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_7_12000.pt\n",
      "2023-10-13 10:18:43,729 - Training - INFO - Deleting checkpoint d:\\MMSERA\\notebooks\\checkpoints\\bert_vggish_MMSERA\\20231013-090144\\weights\\checkpoint_7_12000.pt\n",
      "loss: 1.1603 acc: 0.5000 : : 1522it [06:10,  4.10it/s]                         \n",
      "Epoch 10 - loss: 0.9168\n",
      "2023-10-13 10:21:28,024 - Training - INFO - Epoch 10 - loss: 0.9168\n",
      "Epoch 10 - acc: 0.6552\n",
      "2023-10-13 10:21:28,027 - Training - INFO - Epoch 10 - acc: 0.6552\n",
      "Performing validation...\n",
      "2023-10-13 10:21:28,031 - Training - INFO - Performing validation...\n",
      "100%|##########| 679/679 [00:53<00:00, 12.77it/s]\n",
      "Validation: loss: 1.0224 acc: 0.6200 \n",
      "2023-10-13 10:22:21,321 - Training - INFO - Validation: loss: 1.0224 acc: 0.6200 \n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_ds, opt.num_epochs, test_ds, callbacks=[ckpt_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3m-ser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
