{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-29T13:01:10.421065900Z",
     "start_time": "2023-08-29T13:01:10.398937500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import speech_recognition as sr\n",
    "    import whisper\n",
    "    print('sucess')\n",
    "except:\n",
    "    print('fail!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "path = \"D:/Dataset/TESS Toronto emotional speech set data/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T13:01:12.105093500Z",
     "start_time": "2023-08-29T13:01:12.089150400Z"
    }
   },
   "id": "9ffca44dc91102d6"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f67e1523f19e95e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m directories:\n\u001B[0;32m      9\u001B[0m     part \u001B[38;5;241m=\u001B[39m file\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 10\u001B[0m     part \u001B[38;5;241m=\u001B[39m \u001B[43mpart\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m part\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mps\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     12\u001B[0m         file_emotion\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurprise\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tess_directory_list = os.listdir(path)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(path + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(path + dir + '/' + file)\n",
    "\n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([path_df, emotion_df], axis=1)\n",
    "\n",
    "csv_filename = \"tess_data.csv\"\n",
    "Tess_df.to_csv(csv_filename, index=False, sep=',')\n",
    "\n",
    "Tess_df.tail(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T13:01:16.223618200Z",
     "start_time": "2023-08-29T13:01:15.909456300Z"
    }
   },
   "id": "42defeeb1ebe9c90"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert speech2text using whisper of OpenAI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6be774dc05a61dac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Convert speech2text using whisper of OpenAI\n",
    "tess_directory_list = os.listdir(path)\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "file_path = \"script_tess.txt\"\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(path + dir)\n",
    "\n",
    "    for file in directories:\n",
    "        if file.endswith('.wav'):\n",
    "            result = model.transcribe(os.path.join(path, dir, file))\n",
    "            print(result[\"text\"])\n",
    "            if result[\"text\"] is not None:\n",
    "                with open(file_path, 'a', encoding='utf-8') as file:  \n",
    "                    file.write(f'{result[\"text\"]}\\n')\n",
    "        else:\n",
    "            continue"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "748f9c0410c3da06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# using speech_recognition to convert speech2text with 4 emotions angry, happy, sad, neutral"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93607fa8e05d3cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(path)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "file_path_another = []\n",
    "file_another = []\n",
    "file_script = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(path + dir)\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_another.append('surprise')\n",
    "            file_path_another.append(path + dir + '/' + file)\n",
    "        elif part=='fear':\n",
    "            file_another.append('fear')\n",
    "            file_path_another.append(path + dir + '/' + file)\n",
    "        elif part=='disgust':\n",
    "            file_another.append('disgust')\n",
    "            file_path_another.append(path + dir + '/' + file)\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "            file_path.append(path + dir + '/' + file)\n",
    "            with sr.AudioFile(os.path.join(path, dir, file)) as source:\n",
    "                audio = r.record(source)\n",
    "                try:\n",
    "                    text = r.recognize_google(audio)\n",
    "                    file_script.append(text)\n",
    "                #                         print(\"Văn bản nhận dạng từ âm thanh:\", text)\n",
    "                except sr.UnknownValueError:\n",
    "                    file_script.append(\"Không thể nhận dạng giọng nói\")\n",
    "        #                         print(\"Không thể nhận dạng giọng nói\")\n",
    "        print(len(file_emotion), len(file_script), len(file_path))\n",
    "\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "script_df = pd.DataFrame(file_script, columns=['Script'])\n",
    "Tess_df_select = pd.concat([path_df, script_df, emotion_df], axis=1)\n",
    "\n",
    "Tess_df_select.tail(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c50812d017982ce1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
