{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "lib_path = os.path.abspath(\"\").replace(\"notebooks\", \"src\")\n",
    "sys.path.append(lib_path)\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score,confusion_matrix\n",
    "from transformers import BertTokenizer\n",
    "from data.dataloader import build_train_test_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from models import networks\n",
    "from transformers import BertTokenizer, RobertaTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(opt, checkpoint_path, tokenizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    network = getattr(networks, opt.model_type)(\n",
    "                num_classes=opt.num_classes,\n",
    "                num_attention_head=opt.num_attention_head,\n",
    "                dropout=opt.dropout,\n",
    "                text_encoder_type=opt.text_encoder_type,\n",
    "                text_encoder_dim=opt.text_encoder_dim,\n",
    "                text_unfreeze=opt.text_unfreeze,\n",
    "                audio_encoder_type=opt.audio_encoder_type,\n",
    "                audio_encoder_dim=opt.audio_encoder_dim,\n",
    "                audio_unfreeze=opt.audio_unfreeze,\n",
    "                audio_norm_type=opt.audio_norm_type,\n",
    "                fusion_head_output_type=opt.fusion_head_output_type,\n",
    "            )\n",
    "    network.to(device)\n",
    "\n",
    "    # Build dataset\n",
    "    _, test_ds = build_train_test_dataset(\n",
    "        opt.data_root,\n",
    "        opt.batch_size,\n",
    "        tokenizer,\n",
    "        opt.audio_max_length,\n",
    "        text_max_length=opt.text_max_length,\n",
    "        audio_encoder_type=opt.audio_encoder_type,\n",
    "    )\n",
    "    # Load checkpoint with save_all_states = False\n",
    "    # network.load_state_dict(torch.load(checkpoint_path, map_location=torch.device(device)).state_dict())\n",
    "    # Load checkpoint with save_all_states = True\n",
    "    network.load_state_dict(torch.load(checkpoint_path, map_location=torch.device(device))[\"state_dict_backbone\"])\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    y_actu=[]\n",
    "    y_pred=[]\n",
    "\n",
    "    for every_test_list in tqdm(test_ds):\n",
    "        input_ids, audio, label = every_test_list\n",
    "        input_ids = input_ids.to(device)\n",
    "        audio = audio.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = network(input_ids,audio)[0]\n",
    "            _, preds = torch.max(output, 1)\n",
    "            y_actu.append(label.detach().cpu().numpy()[0])\n",
    "            y_pred.append(preds.detach().cpu().numpy()[0])\n",
    "    print(accuracy_score(y_actu, y_pred))\n",
    "    wa = balanced_accuracy_score(y_actu, y_pred)\n",
    "    ua = accuracy_score(y_actu, y_pred)\n",
    "    print(\"Balanced Accuracy: \", wa)\n",
    "    print(\"Accuracy: \", ua)\n",
    "    cm = confusion_matrix(y_actu, y_pred)\n",
    "    print(cm)\n",
    "    cmn = (cm.astype('float') / cm.sum(axis=1)[:, np.newaxis])*100\n",
    "    print (cmn)\n",
    "# Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "# Create a heatmap\n",
    "    cax = ax.matshow(cmn, cmap='Blues')\n",
    "\n",
    "# Add color bar\n",
    "    plt.colorbar(cax)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "# Set x and y axis ticks\n",
    "    plt.xticks(np.arange(4), [\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"])\n",
    "    plt.yticks(np.arange(4), [\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"])\n",
    "\n",
    "# Display the values in each cell\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            plt.text(j, i, format(cmn[i, j], '.2f'),\n",
    "                 ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.bert_vggish import Config as roberta_wav2vec2_config\n",
    "\n",
    "checkpoint_path = \"D:/SER_ICIIT_2024/notebooks\\checkpoints/bert_vggish_MMSERA/20231007-161007\" #check point\n",
    "opt_path = os.path.join(checkpoint_path,\"opt.log\")\n",
    "with open(opt_path, \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "    # remove all empty strings\n",
    "    data = list(filter(None, data))\n",
    "    # convert to dict\n",
    "    data_dict ={}\n",
    "    for i in range(len(data)):\n",
    "        key, value = data[i].split(\":\")[0].strip(), data[i].split(\":\")[1].strip()\n",
    "        if '.' in value and value.replace('.', '').isdigit():\n",
    "            value = float(value)\n",
    "        elif value.isdigit():\n",
    "            value = int(value)\n",
    "        elif value == 'True':\n",
    "            value = True\n",
    "        elif value == 'False':\n",
    "            value = False\n",
    "        elif value == 'None':\n",
    "            value = None\n",
    "        data_dict[key] = value\n",
    "# Load checkpoint with save_all_states = False\n",
    "ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0_0.pt\")\n",
    "# Load checkpoint with save_all_states = False\n",
    "# ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0.pt\")\n",
    "opt = roberta_wav2vec2_config()\n",
    "# Replace the default config with the loaded config\n",
    "for key, value in data_dict.items():\n",
    "    setattr(opt, key, value)\n",
    "    \n",
    "# Set dataset path\n",
    "opt.data_root=\"data/IEMOCAP/\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "eval(opt, ckpt_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 20230919-112345 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# after 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the confusion matrix\n",
    "confusion_matrix = np.array([[78.53107345, 6.77966102, 0., 14.68926554],\n",
    "                             [7.11743772, 72.59786477, 3.91459075, 16.37010676],\n",
    "                             [2.45098039, 5.39215686, 78.43137255, 13.7254902],\n",
    "                             [5.53505535, 14.02214022, 11.43911439, 69.00369004]])\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create a heatmap\n",
    "cax = ax.matshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(cax)\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "# Set x and y axis ticks\n",
    "plt.xticks(np.arange(4), [\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"])\n",
    "plt.yticks(np.arange(4), [\"Anger\", \"Happiness\", \"Sadness\", \"Neutral\"])\n",
    "\n",
    "# Display the values in each cell\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        plt.text(j, i, format(confusion_matrix[i, j], '.2f'),\n",
    "                 ha='center', va='center', color='black', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints /mnt/d/SER_ICIIT_2024/notebooks/checkpoints/bert_vggish_MMSERA/20230919-112345/weights/checkpoint_2_8000.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the confusion matrix\n",
    "confusion_matrix = np.array([[78.53107345, 6.77966102, 0., 14.68926554],\n",
    "                             [7.11743772, 72.59786477, 3.91459075, 16.37010676],\n",
    "                             [2.45098039, 5.39215686, 78.43137255, 13.7254902],\n",
    "                             [5.53505535, 14.02214022, 11.43911439, 69.00369004]])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def unweighted_accuracy(confusion_matrix):\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    total = confusion_matrix.sum()\n",
    "    accuracy = sum(TP) / total\n",
    "    return accuracy\n",
    "\n",
    "def weighted_accuracy(confusion_matrix):\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    class_counts = confusion_matrix.sum(axis=1)\n",
    "    \n",
    "    # Calculate accuracy for each class and weight it by the class frequency\n",
    "    class_accuracies = [TP[i] / class_counts[i] if class_counts[i] > 0 else 0 for i in range(len(TP))]\n",
    "    \n",
    "    weighted_accuracy = sum(class_accuracies) / len(class_accuracies)\n",
    "    return weighted_accuracy\n",
    "\n",
    "# Example confusion matrix (replace this with your actual confusion matrix)\n",
    "confusion_matrix = np.array([[78.53107345, 6.77966102, 0., 14.68926554],\n",
    "                             [7.11743772, 72.59786477, 3.91459075, 16.37010676],\n",
    "                             [2.45098039, 5.39215686, 78.43137255, 13.7254902],\n",
    "                             [5.53505535, 14.02214022, 11.43911439, 69.00369004]])\n",
    "\n",
    "unweighted_acc = unweighted_accuracy(confusion_matrix)\n",
    "weighted_acc = weighted_accuracy(confusion_matrix)\n",
    "\n",
    "print(\"Unweighted Accuracy:\", unweighted_acc)\n",
    "print(\"Weighted Accuracy:\", weighted_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.bert_vggish import Config as roberta_wav2vec2_config\n",
    "\n",
    "checkpoint_path = \"/mnt/d/SER_ICIIT_2024/notebooks/checkpoints/bert_vggish_MMSERA/20230919-155447\" #check point\n",
    "opt_path = os.path.join(checkpoint_path,\"opt.log\")\n",
    "with open(opt_path, \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "    # remove all empty strings\n",
    "    data = list(filter(None, data))\n",
    "    # convert to dict\n",
    "    data_dict ={}\n",
    "    for i in range(len(data)):\n",
    "        key, value = data[i].split(\":\")[0].strip(), data[i].split(\":\")[1].strip()\n",
    "        if '.' in value and value.replace('.', '').isdigit():\n",
    "            value = float(value)\n",
    "        elif value.isdigit():\n",
    "            value = int(value)\n",
    "        elif value == 'True':\n",
    "            value = True\n",
    "        elif value == 'False':\n",
    "            value = False\n",
    "        elif value == 'None':\n",
    "            value = None\n",
    "        data_dict[key] = value\n",
    "# Load checkpoint with save_all_states = False\n",
    "ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0_0.pt\")\n",
    "# Load checkpoint with save_all_states = False\n",
    "# ckpt_path = os.path.join(checkpoint_path,\"weights/best_acc/checkpoint_0.pt\")\n",
    "opt = roberta_wav2vec2_config()\n",
    "# Replace the default config with the loaded config\n",
    "for key, value in data_dict.items():\n",
    "    setattr(opt, key, value)\n",
    "    \n",
    "# Set dataset path\n",
    "opt.data_root=\"data/IEMOCAP/\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "eval(opt, ckpt_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def unweighted_accuracy(confusion_matrix):\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    total = confusion_matrix.sum()\n",
    "    accuracy = sum(TP) / total\n",
    "    return accuracy\n",
    "\n",
    "def weighted_accuracy(confusion_matrix):\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    class_counts = confusion_matrix.sum(axis=1)\n",
    "    \n",
    "    # Calculate accuracy for each class and weight it by the class frequency\n",
    "    class_accuracies = [TP[i] / class_counts[i] if class_counts[i] > 0 else 0 for i in range(len(TP))]\n",
    "    \n",
    "    weighted_accuracy = sum(class_accuracies) / len(class_accuracies)\n",
    "    return weighted_accuracy\n",
    "\n",
    "# Example confusion matrix (replace this with your actual confusion matrix)\n",
    "confusion_matrix = np.array([[76.83615819,  8.47457627,  5.64971751,  9.03954802],\n",
    " [3.55871886, 76.15658363,  7.82918149, 12.45551601],\n",
    " [1.96078431,  2.94117647, 91.17647059,  3.92156863],\n",
    " [6.64206642, 15.49815498, 22.87822878, 54.98154982]])\n",
    "\n",
    "unweighted_acc = unweighted_accuracy(confusion_matrix)\n",
    "weighted_acc = weighted_accuracy(confusion_matrix)\n",
    "\n",
    "print(\"Unweighted Accuracy:\", unweighted_acc)\n",
    "print(\"Weighted Accuracy:\", weighted_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
